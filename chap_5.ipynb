{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e83568bdc05e48528f4c92dd496b22cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98edfc2cc46040019cf478c49f6b76d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004818c4454d4635a2a669e637ab6b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de0e6a2b21e46b6acf5c1ac2d5a1d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9f8aeae2f448599a85d4025dd20af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/523M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_name = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy Search Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>Choice 1</th>\n",
       "      <th>Choice 2</th>\n",
       "      <th>Choice 3</th>\n",
       "      <th>Choice 4</th>\n",
       "      <th>Choice 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transformers are the</td>\n",
       "      <td>vern ( 14.87%</td>\n",
       "      <td>( 11.98%</td>\n",
       "      <td>ids ( 7.52%</td>\n",
       "      <td>ices ( 4.99%</td>\n",
       "      <td>urs ( 4.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transformers are the vern</td>\n",
       "      <td>acular ( 94.56%</td>\n",
       "      <td>al ( 3.49%</td>\n",
       "      <td>ier ( 1.01%</td>\n",
       "      <td>iers ( 0.16%</td>\n",
       "      <td>us ( 0.08%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transformers are the vernacular</td>\n",
       "      <td>of ( 28.65%</td>\n",
       "      <td>for ( 17.40%</td>\n",
       "      <td>term ( 5.95%</td>\n",
       "      <td>name ( 5.18%</td>\n",
       "      <td>words ( 2.47%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transformers are the vernacular of</td>\n",
       "      <td>the ( 22.59%</td>\n",
       "      <td>all ( 1.54%</td>\n",
       "      <td>a ( 1.45%</td>\n",
       "      <td>our ( 0.75%</td>\n",
       "      <td>this ( 0.69%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transformers are the vernacular of the</td>\n",
       "      <td>game ( 1.31%</td>\n",
       "      <td>time ( 1.14%</td>\n",
       "      <td>world ( 1.08%</td>\n",
       "      <td>modern ( 0.92%</td>\n",
       "      <td>ancient ( 0.71%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transformers are the vernacular of the game</td>\n",
       "      <td>. ( 25.34%</td>\n",
       "      <td>, ( 22.62%</td>\n",
       "      <td>'s ( 8.07%</td>\n",
       "      <td>and ( 5.68%</td>\n",
       "      <td>world ( 4.95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transformers are the vernacular of the game.</td>\n",
       "      <td>\\n ( 15.49%</td>\n",
       "      <td>They ( 11.45%</td>\n",
       "      <td>The ( 8.13%</td>\n",
       "      <td>In ( 2.92%</td>\n",
       "      <td>It ( 2.64%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transformers are the vernacular of the game.\\n</td>\n",
       "      <td>\\n ( 99.65%</td>\n",
       "      <td>The ( 0.04%</td>\n",
       "      <td>A ( 0.02%</td>\n",
       "      <td>I ( 0.01%</td>\n",
       "      <td>In ( 0.01%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            input         Choice 1  \\\n",
       "0                           Transformers are the     vern ( 14.87%   \n",
       "1                       Transformers are the vern  acular ( 94.56%   \n",
       "2                 Transformers are the vernacular      of ( 28.65%   \n",
       "3              Transformers are the vernacular of     the ( 22.59%   \n",
       "4          Transformers are the vernacular of the     game ( 1.31%   \n",
       "5     Transformers are the vernacular of the game       . ( 25.34%   \n",
       "6    Transformers are the vernacular of the game.      \\n ( 15.49%   \n",
       "7  Transformers are the vernacular of the game.\\n      \\n ( 99.65%   \n",
       "\n",
       "         Choice 2        Choice 3         Choice 4          Choice 5  \n",
       "0      Â  ( 11.98%     ids ( 7.52%     ices ( 4.99%       urs ( 4.02%  \n",
       "1      al ( 3.49%     ier ( 1.01%     iers ( 0.16%        us ( 0.08%  \n",
       "2    for ( 17.40%    term ( 5.95%     name ( 5.18%     words ( 2.47%  \n",
       "3     all ( 1.54%       a ( 1.45%      our ( 0.75%      this ( 0.69%  \n",
       "4    time ( 1.14%   world ( 1.08%   modern ( 0.92%   ancient ( 0.71%  \n",
       "5      , ( 22.62%      's ( 8.07%      and ( 5.68%     world ( 4.95%  \n",
       "6   They ( 11.45%     The ( 8.13%       In ( 2.92%        It ( 2.64%  \n",
       "7     The ( 0.04%       A ( 0.02%        I ( 0.01%        In ( 0.01%  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_txt = 'Transformers are the '\n",
    "input_ids = tokenizer(input_txt, return_tensors='pt')['input_ids'].to(device)\n",
    "iterations = []\n",
    "n_steps = 8\n",
    "choices_per_step = 5\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(n_steps):\n",
    "        iteration = {'input': tokenizer.decode(input_ids[0])}\n",
    "        output = model(input_ids=input_ids)\n",
    "\n",
    "        next_token_logits = output.logits[0, -1, :]\n",
    "        next_token_probas = torch.softmax(next_token_logits, dim=-1)\n",
    "        sorted_ids = torch.argsort(next_token_probas, dim=-1, descending=True)\n",
    "\n",
    "        for choice_idx in range(choices_per_step):\n",
    "            token_id = sorted_ids[choice_idx]\n",
    "            token_prob = next_token_probas[token_id].cpu().numpy()\n",
    "            token_choice = (\n",
    "                f'{tokenizer.decode(token_id)} ({100 * token_prob: .2f}%'\n",
    "            )\n",
    "            iteration[f'Choice {choice_idx+1}'] = token_choice\n",
    "\n",
    "        input_ids = torch.cat([input_ids, sorted_ids[None, 0, None]], dim=-1)\n",
    "        iterations.append(iteration)\n",
    "\n",
    "df = pd.DataFrame(iterations)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers are the vernacular of the game.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(input_txt, return_tensors='pt')['input_ids'].to(device)\n",
    "output = model.generate(input_ids, max_new_tokens=n_steps, do_sample=False)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam Search Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more suprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "\"The unicorns were very intelligent, and they were very intelligent,\" said Dr. David S. Siegel, a professor of anthropology at the University of California, Berkeley. \"They were very intelligent, and they were very intelligent. They were very intelligent, and they were very intelligent.\"\n",
      "\n",
      "\n",
      "The researchers found that the unicorns were able to communicate with each other through their vocal cords, which\n"
     ]
    }
   ],
   "source": [
    "max_length = 128\n",
    "input_txt = \"\"\"In a shocking finding, scientist discovered \\\n",
    "a herd of unicorns living in a remote, previously unexplored \\\n",
    "valley, in the Andes Mountains. Even more suprising to the \\\n",
    "researchers was the fact that the unicorns spoke perfect English.\\n\\n\n",
    "\"\"\"\n",
    "input_ids = tokenizer(input_txt, return_tensors='pt')['input_ids'].to(device)\n",
    "output = model.generate(input_ids, max_length=max_length, do_sample=False)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_probs_from_logits(logits, labels):\n",
    "    logp = F.log_softmax(logits, dim=-1)\n",
    "    logp_label = torch.gather(logp, dim=2, index=labels.unsqueeze(2)).squeeze(-1)\n",
    "    return logp_label\n",
    "\n",
    "\n",
    "def sequence_logprob(model, labels, input_len=0):\n",
    "    with torch.no_grad():\n",
    "        output = model(labels)\n",
    "        log_probs = log_probs_from_logits(output.logits[:, :-1, :], labels[:, 1:])\n",
    "        seq_logprob = torch.sum(log_probs[:, input_len:])\n",
    "    return seq_logprob.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more suprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "Advertisement\n",
      "\n",
      "Now, researchers are asking whether the unicorns might even have been part of a mysterious and extremely elaborate civilization of prehistoric beings. The results suggest that they might even be extinct.\n",
      "\n",
      "\n",
      "The researchers looked at the genome of two male and two female unicorns in the Andes Mountains, which is the only part of the world without unicorns. The two animals lived in herds, but\n",
      "log-prob: -171.05\n"
     ]
    }
   ],
   "source": [
    "# greedy search\n",
    "logp = sequence_logprob(model, output, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output[0]))\n",
    "print(f'log-prob: {logp: .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more suprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "According to the researchers, the unicorns were able to communicate with each other in a way that was similar to that of humans. The unicorns were able to communicate with each other in a way that was similar to that of humans. The unicorns were able to communicate with each other in a way that was similar to that of humans. The unicorns were able to communicate with each other in a\n",
      "log-prob: -47.81\n"
     ]
    }
   ],
   "source": [
    "# beam search\n",
    "output = model.generate(input_ids, max_length=max_length, num_beams=5, do_sample=False)\n",
    "logp = sequence_logprob(model, output, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output[0]))\n",
    "print(f'log-prob: {logp: .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more suprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The researchers, from the University of California, San Diego, and the National Science Foundation (NSF) in Boulder, Colorado, were able to translate the words of the unicorn into English, which they then translated into Spanish.\n",
      "\n",
      "\"This is the first time that we have translated a language into an English language,\" said study co-author and NSF professor of linguistics and evolutionary biology Dr\n",
      "log-prob: -102.25\n"
     ]
    }
   ],
   "source": [
    "# beam search, no repeat ngrams\n",
    "output = model.generate(\n",
    "    input_ids, max_length=max_length, num_beams=5, do_sample=False, no_repeat_ngram_size=2\n",
    ")\n",
    "logp = sequence_logprob(model, output, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output[0]))\n",
    "print(f'log-prob: {logp: .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more suprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "\"They were actually able to tell if their language contained real language,\" says Toni M. Janssen, a University of Pennsylvania linguist who spoke with the New York Times. \"They started using it as they approached the area. The only missing word is \"fantastic\" or \"kind.\"\n",
      "\n",
      "The unicorns are believed to be from the eastern and northern Rockies of Mexico,\n",
      "log-prob: -203.54\n"
     ]
    }
   ],
   "source": [
    "# top k samp,ing\n",
    "output = model.generate(\n",
    "    input_ids, max_length=max_length, do_sample=True, top_k=50\n",
    ")\n",
    "logp = sequence_logprob(model, output, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output[0]))\n",
    "print(f'log-prob: {logp: .2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more suprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The results show that the unicorns actually prefer the familiar English language, but do not share a common ancestor with human beings. Moreover, the unicorns are very fast and they can reach heights up to 600 meters.\n",
      "\n",
      "\n",
      "In fact, the researchers observed that this amazing animal had more in common with humans than they expected. Although they do not believe humans are directly related, the fact is that these\n",
      "log-prob: -187.75\n"
     ]
    }
   ],
   "source": [
    "# top k and nucleus sampling\n",
    "output = model.generate(\n",
    "    input_ids, max_length=max_length, do_sample=True, top_k=50, top_p=0.9\n",
    ")\n",
    "logp = sequence_logprob(model, output, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output[0]))\n",
    "print(f'log-prob: {logp: .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
